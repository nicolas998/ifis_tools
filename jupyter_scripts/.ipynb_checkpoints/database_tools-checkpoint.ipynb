{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# database_tools:\n",
    "\n",
    "Set of tools to connect to the data base, put and get data from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "from ifis_tools import auxiliar as aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def DataBaseConnect(user = \"iihr_student\", password = \"iihr.student\", host = \"s-iihr51.iihr.uiowa.edu\",\n",
    "    port = \"5435\", database = \"research_environment\"):\n",
    "    '''Connect to the database that hsa stored the usgs information'''\n",
    "    con = psycopg2.connect(user = user,\n",
    "        password = password,\n",
    "        host = host,\n",
    "        port = port,\n",
    "        database = database)\n",
    "    return con\n",
    "\n",
    "def SQL_read_USGS_Streamflow(usgs_id, date1, date2, schema = 'pers_nico', \n",
    "    table = 'data_usgs', time_name = 'unix_time', data_name = 'val', usgs_name = 'usgs_id'):\n",
    "    '''Read streamflow data from IIHR database \"research_environment\" \n",
    "    and returns it as a pandas.DataFrame element.\n",
    "    Parameters:\n",
    "        - usgs_id: code of the usgs.\n",
    "        - date1: initial date of the query.\n",
    "        - date2: final date of the query.\n",
    "    Optional:\n",
    "        - schema: where to obtain data in the databse.\n",
    "        - table: master table with the usgs data.\n",
    "        - time_name: the name of the column that has the time.\n",
    "        - data_name: the name of the column that has the data.\n",
    "        - usgs_name: the name of the column that has the id of the usgs stations.\n",
    "    Returns:\n",
    "        - pandas.DataFrame containing the streamflow data.'''\n",
    "    #make the connection\n",
    "    con = DataBaseConnect(user = 'nicolas', password = '10A28Gir0')\n",
    "    #Work with dates and usgs id\n",
    "    date1 = str(aux.__datetime2unix__(date1))\n",
    "    date2 = str(aux.__datetime2unix__(date2))\n",
    "    if type(usgs_id) is not str:\n",
    "        usgs_id = str(usgs_id)\n",
    "    #make the querty\n",
    "    query = sql.SQL(\"SELECT \"+time_name+\", \"+data_name+\" FROM \"+schema+\".\"+table+\" WHERE \"+time_name+\" BETWEEN \"+date1+\" and \"+date2+\" AND \"+usgs_name+\"='\"+usgs_id+\"'\")\n",
    "    #Make the consult.\n",
    "    Data = pd.read_sql(query, con, index_col='unix_time',parse_dates={'unix_time':{'unit':'s'}})\n",
    "    con.close()\n",
    "    return Data\n",
    "\n",
    "#SQL Query to obtain the data from per_felipe.pois_adv_geom\n",
    "def SQL_USGS_at_IFIS():\n",
    "    '''Return the list of the usgs stations in the IFIS system and the linkID where they \n",
    "    belong.'''\n",
    "    #make the connection\n",
    "    con = DataBaseConnect(user = 'nicolas', password = '10A28Gir0')\n",
    "    #Query for the stations\n",
    "    query = sql.SQL(\"SELECT foreign_id,link_id FROM pers_felipe.pois_adv_geom where type in (2,3) and foreign_id like '0%' AND link_id < 620000\")\n",
    "    #make the consult\n",
    "    cur = con.cursor()\n",
    "    cur.execute(query)\n",
    "    L = cur.fetchall()\n",
    "    cur.close()\n",
    "    con.close()\n",
    "    #Obtains a dictionary in which stations are the key\n",
    "    DicUSGSinIFIS = {}\n",
    "    for l in L:\n",
    "        DicUSGSinIFIS.update({l[0]:l[1]})\n",
    "    return DicUSGSinIFIS\n",
    "\n",
    "def SQL_USGS_at_MATC():\n",
    "    '''Return the list of stations that are in the databse pers_nico (matc).'''\n",
    "    #make the connection\n",
    "    con = DataBaseConnect(user = 'nicolas', password = '10A28Gir0')\n",
    "    #Make the query\n",
    "    query = sql.SQL(\"SELECT DISTINCT(usgs_id) FROM pers_nico.data_usgs_2008\")\n",
    "    cur = con.cursor()\n",
    "    cur.execute(query)\n",
    "    L = cur.fetchall()\n",
    "    cur.close()\n",
    "    con.close()\n",
    "    return [l[0] for l in L]\n",
    "\n",
    "def SQL_Get_linkArea(linkID):\n",
    "    '''Obtains the up area for a link ID'''\n",
    "    #The query and the obtentions\n",
    "    con = DataBaseConnect('nicolas','10A28Gir0')\n",
    "    cur = con.cursor()\n",
    "    q = sql.SQL(\"SELECT upstream_area FROM pers_felipe.pois_adv_geom WHERE link_id = \"+str(linkID))\n",
    "    cur.execute(q)\n",
    "    A = cur.fetchall()\n",
    "    cur.close()\n",
    "    con.close()\n",
    "    return A[0][0]*2.583\n",
    "\n",
    "def SQL_Read_MeanRainfall(link_id, date1, date2, schema = 'pers_nico', \n",
    "    table = 's4mrain', time_name = 'unix_time', data_name = 'rain', linkid_name = 'link_id'):\n",
    "    '''Read streamflow data from IIHR database \"research_environment\" \n",
    "    and returns it as a pandas.DataFrame element.\n",
    "    Parameters:\n",
    "        - usgs_id: code of the usgs.\n",
    "        - date1: initial date of the query.\n",
    "        - date2: final date of the query.\n",
    "    Optional:\n",
    "        - schema: where to obtain data in the databse.\n",
    "        - table: master table with the usgs data.\n",
    "        - time_name: the name of the column that has the time.\n",
    "        - data_name: the name of the column that has the data.\n",
    "        - usgs_name: the name of the column that has the id of the usgs stations.\n",
    "    Returns:\n",
    "        - pandas.DataFrame containing the streamflow data.'''\n",
    "    #make the connection\n",
    "    con = DataBaseConnect(user = 'nicolas', password = '10A28Gir0')\n",
    "    #Work with dates and usgs id\n",
    "    date1 = str(aux.__datetime2unix__(date1))\n",
    "    date2 = str(aux.__datetime2unix__(date2))\n",
    "    if type(link_id) is not str:\n",
    "        link_id = str(link_id)\n",
    "    #make the querty\n",
    "    query = sql.SQL(\"SELECT \"+time_name+\", \"+data_name+\" FROM \"+schema+\".\"+table+\" WHERE \"+time_name+\" BETWEEN \"+date1+\" and \"+date2+\" AND \"+linkid_name+\"='\"+link_id+\"'\")\n",
    "    #Make the consult.\n",
    "    Data = pd.read_sql(query, con, index_col='unix_time',parse_dates={'unix_time':{'unit':'s'}})\n",
    "    con.close()\n",
    "    #Organize rainfall \n",
    "    Data = Data.sort_index()\n",
    "    Dates = pd.date_range(Data.index[0], Data.index[-1], freq='1h')\n",
    "    Rain = pd.Series(np.zeros(Dates.size), Dates)\n",
    "    Rain[Data.index] = Data['rain'].values\n",
    "    Rain[Rain>1000] = 0.0\n",
    "    return Rain\n",
    "\n",
    "def SQL_Get_MeanRainfall(linkID, date1, date2):\n",
    "    '''Obtains the mean rainfall for the watershed associated to \n",
    "    a given linkID.\n",
    "    Parameters:\n",
    "        - linkID: linkID of the outlet of the basin.\n",
    "        - date1: initial date (YYYY-MM-DD HH:MM).\n",
    "        - date2: end date (YYYY-MM-DD HH:MM).\n",
    "    Returns:\n",
    "        - Rainfall: Pandas series with the mean rainfall in the basin.'''\n",
    "    #SEt the connection\n",
    "    con = DataBaseConnect(user='nicolas', password='10A28Gir0', database='rt_precipitation')\n",
    "    #Transform dates to unix \n",
    "    unix1 = str(aux.__datetime2unix__(date1))\n",
    "    unix2 = str(aux.__datetime2unix__(date2))\n",
    "    linkID = str(linkID)\n",
    "    #Set the query and obtains data\n",
    "    q = sql.SQL(\"WITH subbasin AS (SELECT nodeX.link_id AS link_id FROM students.env_master_km AS nodeX, students.env_master_km AS parentX WHERE (nodeX.left BETWEEN parentX.left AND parentX.right) AND parentX.link_id = \"+str(linkID)+\"), uparea as (SELECT up_area FROM students.env_master_km WHERE link_id= \"+str(linkID)+\"), lut as (SELECT x, y FROM env_lookup_hrap_lid_v4 WHERE link_id IN (SELECT * FROM subbasin) group by x, y) SELECT unix_time, sum(val)/(SELECT count(*) FROM lut) as rain FROM stage_4.data WHERE grid_x IN (SELECT x FROM lut) AND grid_y IN (SELECT y from lut) AND unix_time between \"+unix1+\" AND \"+unix2+\" group by unix_time order by unix_time;\")\n",
    "    Data = pd.read_sql(q, con, index_col='unix_time',parse_dates={'unix_time':{'unit':'s'}})\n",
    "    #close connection\n",
    "    con.close()\n",
    "    #Pos process data \n",
    "    dates = pd.date_range(date1, date2, freq='1h')\n",
    "    Rain = pd.Series(np.zeros(dates.size), dates)\n",
    "    Rain[Data.index] = Data['rain'] \n",
    "    return Rain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "jupyter_scripts//ipynb,ifis_tools//py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
