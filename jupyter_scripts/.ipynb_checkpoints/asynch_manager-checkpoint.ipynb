{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# asynch_manager\n",
    "\n",
    "SEt of tools to get data from asynch and set the variables to run the model in an easy way from python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from datetime import timezone, datetime\n",
    "import os \n",
    "import fileinput\n",
    "import numpy as np \n",
    "from ifis_tools import auxiliar as aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEt of parameters for the different configurations of the model \n",
    "Parameters = {'190': [6, 0.75, 0.33, -0.20, 0.50, 0.1, 2.2917e-5],\n",
    "    '254':[12, 0.33, 0.2, -0.1, 0.02, 2.0425e-6, 0.02, 0.5, 0.10, 0.0, 99.0, 3.0, 0.75]}\n",
    "\n",
    "#Path of the file \n",
    "Path = __file__.split('/')\n",
    "Path = '/'.join(Path[:-1])+'/'\n",
    "\n",
    "#Read the global files that are used to generate new globals\n",
    "Globals = {}\n",
    "for g in ['190','254']:    \n",
    "    # 190 global base format \n",
    "    f = open(Path+g+'BaseGlobal.gbl','r')\n",
    "    Globals.update({g:f.readlines()}) \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASYNCH tools  \n",
    "\n",
    "## Asynch results reader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASYNCH_results:\n",
    "    \n",
    "    def __init__(self,path):\n",
    "        '''Reads a .dat file produced by ASYNCH'''\n",
    "        #Open the file \n",
    "        f = open(path,'r')\n",
    "        self.dat = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "    def ASYNCH_dat2Serie(self, linkID, date1, freq):\n",
    "        '''From the data readed with ASYNCH_read_dat reads the serie \n",
    "        corresponding to the linkID and retrieves a pandas Series object.\n",
    "        Parameters:\n",
    "            - linkID: the number of the linkID to obtain.\n",
    "            - date1: the start date of the simulation.\n",
    "            - freq: time frequency of the data (ej. 15min).\n",
    "        Returns: \n",
    "            - Pandas series with the simulated data.'''\n",
    "        #Number of records\n",
    "        self.Nlinks = int(self.dat[0])\n",
    "        self.Nrec = int(self.dat[3].split()[1])\n",
    "        Start = np.arange(3, (self.Nrec+2)*self.Nlinks, self.Nrec+2)\n",
    "        End = Start + self.Nrec\n",
    "        #Search the IDS\n",
    "        self.Ids = [l.split()[0] for l in self.dat[3::self.Nrec+2]]\n",
    "        #Search the position of the usgs station to be analyzed.\n",
    "        PosStat = self.Ids.index(str(linkID))\n",
    "        #Retrieve the data.\n",
    "        Data = np.array([float(l) for l in self.dat[Start[PosStat]+1:End[PosStat]+1]])\n",
    "        #return self.dat[Start[PosStat]+1:End[PosStat]+1]\n",
    "        Dates = pd.date_range(date1, periods=self.Nrec, freq=freq)\n",
    "        return pd.Series(Data, Dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynch project manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASYNCH_project:\n",
    "    \n",
    "    def __init__(self, path_in, path_out, name = None, date1 = None, date2 = None, \n",
    "        linkID = 0, unix1 = None, unix2 = None, model = '190',\n",
    "        parameters = None, links2save = 'ControlPoints.sav'):\n",
    "        '''ASYNCH project constructor, this class creates the folders and files \n",
    "        for an ASYNCH run, and also eventually runs asynch from python (this is not\n",
    "        a warp from C)\n",
    "        Parameters:\n",
    "            - path_in: path to store: Global file, initial file and run file.\n",
    "            - path_out: path to store: hydrographs.\n",
    "            - name: The name of the project with the path to save it\n",
    "            - date1: the initial date of the simulation (YYYY-MM-DD HH:MM)\n",
    "            - date2: the initial date of the simulation (YYYY-MM-DD HH:MM)\n",
    "            - linkID: the number of the output link to make the simulation.\n",
    "            - glbOut: rute and name of the output global file for asynch.\n",
    "            - output: name of the file with the outputs.\n",
    "            - peakflow: name of the file containing the links where to save.\n",
    "        '''\n",
    "        #Paths and name of the project\n",
    "        self.path_in = path_in\n",
    "        self.path_out = path_out\n",
    "        self.name = name\n",
    "        # Dates and linkID of the outlet \n",
    "        self.date1 = date1\n",
    "        self.date2 = date2\n",
    "        self.linkID = linkID\n",
    "        self.unix1 = unix1\n",
    "        self.unix2 = unix2\n",
    "        #Model to use, parameters and where to save\n",
    "        self.model = model\n",
    "        self.parameters = [str(i) for i in Parameters[model]]\n",
    "        self.links2save = links2save\n",
    "        \n",
    "    def ASYNCH_setRunFile(self, runBase = 'BaseRun.sh', path2gbl = None, nprocess = 28):\n",
    "        '''Writes the runfile to the AsynchInput directory of the project'''\n",
    "        #Copy the run file from the base \n",
    "        self.path_in_run = self.path_in + '/' + self.name + '.sh'\n",
    "        comand = 'cp '+Path+runBase+' '+self.path_in_run\n",
    "        os.system(comand)\n",
    "        # Filename to write the new runfile\n",
    "        filename = self.path_in_run\n",
    "        #Dictionary with the words to search and change in the new runfile\n",
    "        if path2gbl is None:\n",
    "            DicToReplace = {'glbFile':{'to_search': '¿global?', 'to_put': self.name+'.gbl'}}\n",
    "        else:\n",
    "            DicToReplace = {'glbFile':{'to_search': '¿global?', 'to_put': path2gbl + self.name+'.gbl'}}\n",
    "        DicToReplace.update({'nProcess':{'to_search': '¿nprocess?', 'to_put': str(nprocess)}})\n",
    "        DicToReplace.update({'name2identify':{'to_search': '¿name2identify?', 'to_put': 'r'+self.name}})\n",
    "        #Changing the runfile.    \n",
    "        for k in DicToReplace:            \n",
    "            with fileinput.FileInput(filename, inplace=True) as file:\n",
    "                for line in file:                    \n",
    "                    text_to_search = DicToReplace[k]['to_search']\n",
    "                    replacement_text = str(DicToReplace[k]['to_put'])\n",
    "                    print(line.replace(text_to_search, replacement_text), end='')\n",
    "            \n",
    "    def ASYNCH_setGlobal(self, gblBase = 'BaseGlobal.gbl', Links2SaveName = 'ControlPoints.sav',\n",
    "        OutStatesName = 'OutputStates.dat', createInitial = True, oldInitial = None):\n",
    "        '''Edit the global file for asynch run.\n",
    "        Parameters:\n",
    "            - date1: the initial date of the simulation (YYYY-MM-DD HH:MM)\n",
    "            - date2: the initial date of the simulation (YYYY-MM-DD HH:MM)\n",
    "            - linkID: the number of the output link to make the simulation.\n",
    "            - glbOut: rute and name of the output global file for asynch.\n",
    "            - output: name of the file with the outputs.\n",
    "            - peakflow: name of the file containing the links where to save.\n",
    "        Optional:\n",
    "            - parameters: running parameters for ASYNCH model.\n",
    "            - unix1: start time of the execution.\n",
    "            - unix2: end time of the execution.\n",
    "            - glbBase: rute and name of the base globl file used for the excecutions.\n",
    "        Outputs:\n",
    "            This function writes a gbl file where gblOut indicates.'''\n",
    "        # Copy the base global to a glbOut\n",
    "        self.path_in_global = self.path_in +  self.name + '.gbl'\n",
    "        comand = 'cp '+Path+self.model+gblBase+' '+self.path_in_global\n",
    "        os.system(comand)\n",
    "        #Copy the links2save file \n",
    "        self.path_in_links2save = self.path_in + Links2SaveName\n",
    "        comand = 'cp '+Path+self.links2save+' '+self.path_in_links2save\n",
    "        os.system(comand)\n",
    "        #Set of the initial file for that link \n",
    "        if createInitial:\n",
    "            self.path_in_initial = self.path_in + self.name + '.dbc'\n",
    "            self.__ASYNCH_setInitialFile__(self.path_in_initial,self.date1[:4],\n",
    "                self.linkID)\n",
    "        else:\n",
    "            self.path_in_initial = oldInitial\n",
    "        #Set the name of the file with the output of the streamflow\n",
    "        self.path_out_states = self.path_out + OutStatesName\n",
    "        # Unix time are equal to date\n",
    "        if self.unix1 is None:\n",
    "            self.unix1 = aux.__datetime2unix__(self.date1) + 12*3600.\n",
    "        textUnix1 = '%d' % self.unix1\n",
    "        if self.unix2 is None:\n",
    "            self.unix2 =aux.__datetime2unix__(self.date2) + 12*3600\n",
    "        textUnix2 = '%d' % self.unix2\n",
    "        # Parameters \n",
    "        Param = ' '.join(self.parameters)+'\\n'\n",
    "        # Replace parameters in the global file        \n",
    "        DicToreplace = {'date1':{'to_search': '¿date1?', 'to_put': self.date1},\n",
    "            'date2':{'to_search': '¿date2?', 'to_put': self.date2},\n",
    "            'unix1':{'to_search': '¿unix1?', 'to_put': textUnix1},\n",
    "            'unix2':{'to_search': '¿unix2?', 'to_put': textUnix2},\n",
    "            'linkID':{'to_search': '¿linkID?', 'to_put': self.linkID},\n",
    "            'parameters':{'to_search': '¿Parameters?', 'to_put': Param},\n",
    "            'output':{'to_search': '¿output?', 'to_put': self.path_out_states},\n",
    "            'peakflow':{'to_search': '¿peakflow?', 'to_put': self.path_in_links2save},\n",
    "            'initial':{'to_search': '¿initial?', 'to_put': self.path_in_initial}}\n",
    "        # Replacement in the document.\n",
    "        filename = self.path_in_global\n",
    "        for k in DicToreplace:            \n",
    "            with fileinput.FileInput(filename, inplace=True) as file:\n",
    "                for line in file:                    \n",
    "                    text_to_search = DicToreplace[k]['to_search']\n",
    "                    replacement_text = str(DicToreplace[k]['to_put'])\n",
    "                    print(line.replace(text_to_search, replacement_text), end='')\n",
    "        \n",
    "    def __ASYNCH_setInitialFile__(self, InitialOut, year, linkID):\n",
    "        '''Set the dbc query for the initial conditions for asynch\n",
    "        Parameters:\n",
    "            - InitialOut: The path and name of the outlet initial file for the dbc.\n",
    "            - linkID: the link in which is going to be placed the initial file.\n",
    "            - InicialBase: Path to the basefile for the stablishment of the initial file.\n",
    "        Results:\n",
    "            - Writes the initial file at InitialOut.'''\n",
    "        # Copy the initial file state in\n",
    "        if linkID == 0:\n",
    "            comando = 'cp '+Path+'BaseInitial.dbc'+' '+InitialOut\n",
    "        else:\n",
    "            comando = 'cp '+Path+'BaseInitial_link.dbc'+' '+InitialOut\n",
    "        os.system(comando)\n",
    "        #Dict with words to replace\n",
    "        DicToreplace = {'link':{'to_search': '¿linkID?', 'to_put': linkID},\n",
    "            'date':{'to_search': 'YYYY', 'to_put': year}}\n",
    "        # Replace the linkID in the initial file so asynch knows.\n",
    "        filename = InitialOut\n",
    "        for k in DicToreplace:          \n",
    "            with fileinput.FileInput(filename, inplace = True) as file:\n",
    "                for line in file:\n",
    "                    text_to_search = DicToreplace[k]['to_search']\n",
    "                    replacement_text = str(DicToreplace[k]['to_put'])\n",
    "                    print(line.replace(text_to_search, replacement_text), end='')\n",
    "# # Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __ASYNC_createProject__(self):\n",
    "    '''Creates a new directory for asynch runs.\n",
    "    Parameters:\n",
    "        - pathProject: path to the new folder conaining the new asynch project\n",
    "    Return:\n",
    "        - Creates a new folder that contains sub-folders and files required \n",
    "            for the asynch run'''\n",
    "    #Creates the main folder of the proyect and inputs and outputs.\n",
    "    aux.__make_folder__(self.path)\n",
    "    self.path_in = self.path + '/AsynchInputs'\n",
    "    aux.__make_folder__(self.path_in)\n",
    "    self.path_out = self.path + '/AsynchOutputs'\n",
    "    aux.__make_folder__(self.path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "jupyter_scripts//ipynb,ifis_tools//py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
