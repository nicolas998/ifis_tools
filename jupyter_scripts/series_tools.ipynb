{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# series_tools:\n",
    "\n",
    "set of tools that work with streamflow records.\n",
    "- Identify events.\n",
    "- Identidy baseflow and runoff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digital filters\n",
    "\n",
    "Collection of functions to separate runoff from baseflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def DigitalFilters(Q,tipo = 'Eckhart', a = 0.98, BFI = 0.8):\n",
    "    '''Digital filters to separate baseflow from runoff in a continuos time series.\n",
    "    Parameters:\n",
    "        - tipo: type of filter to be used.\n",
    "            - Eckhart o 1.\n",
    "            - Nathan o 2.\n",
    "            - Chapman o 3.\n",
    "        - Q: pandas series with the streamflow records.\n",
    "        - a: paramter for the filter.\n",
    "            - Eckhart: 0.98.\n",
    "            - Nathan: 0.8.\n",
    "            - Chapman: 0.8.\n",
    "        - BFI: 0.8 only applies for Eckhart filter.\n",
    "    Returns:\n",
    "        - Pandas DataFrame with the Runoff, Baseflow.'''\n",
    "    #Functions definitions.\n",
    "    def Nathan1990(Q, a = 0.8):\n",
    "        '''One parameter digital filter of Nathan and McMahon (1990)'''\n",
    "        R = np.zeros(Q.size)\n",
    "        c = 1\n",
    "        for q1,q2 in zip(Q[:-1], Q[1:]):\n",
    "            R[c] = a*R[c-1] + ((1+a)/2.)*(q2-q1)\n",
    "            if R[c]<0: \n",
    "                R[c] = 0\n",
    "            elif R[c]>q2:\n",
    "                R[c] = q2 \n",
    "            c += 1\n",
    "        B = Q - R\n",
    "        return R, B\n",
    "\n",
    "    def Eckhart2005(Q, BFI=0.8, a = 0.98):\n",
    "        '''Two parameter Eckhart digital filter\n",
    "        Parameters:\n",
    "            - Q: np.ndarray with the streamflow records.\n",
    "            - BFI: The maximum amount of baseflow (%).\n",
    "            - a: parameter alpha (0.98)\n",
    "        Output: \n",
    "            - R: total runoff.\n",
    "            - B: total baseflow.'''\n",
    "        #SEparation\n",
    "        B = np.zeros(Q.size)\n",
    "        B[0] = Q[0]\n",
    "        c = 1\n",
    "        for q in Q[1:]:\n",
    "            #SEparation equation\n",
    "            B[c] = ((1.0-BFI)*a*B[c-1]+(1.0-a)*BFI*q)/(1.0-a*BFI)\n",
    "            #Constrains\n",
    "            if B[c] > q:\n",
    "                B[c] = q\n",
    "            c+=1\n",
    "        R = Q - B\n",
    "        return R, B\n",
    "\n",
    "    def ChapmanMaxwell1996(Q, a = 0.98):\n",
    "        '''Digital filter proposed by chapman and maxwell (1996)'''\n",
    "        B = np.zeros(Q.size)\n",
    "        c = 1\n",
    "        for q in Q[1:]:\n",
    "            B[c] = (a / (2.-a))*B[c-1] + ((1.-a)/(2.-a))*q\n",
    "            c+=1\n",
    "        R = Q-B\n",
    "        return R,B\n",
    "    \n",
    "    #Cal the filter \n",
    "    if tipo == 'Eckhart' or tipo == 1:\n",
    "        R,B = Eckhart2005(Q.values, a, BFI)\n",
    "    elif tipo =='Nathan' or tipo == 2:\n",
    "        R,B = Nathan1990(Q.values, a,)\n",
    "    elif tipo == 'Chapman' or tipo ==3:\n",
    "        R,B = ChapmanMaxwell1996(Q.values, a)\n",
    "    #Returns the serie\n",
    "    return pd.DataFrame(np.vstack([R,B]).T, index = Q.index, columns = ['Runoff','Baseflow']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events selection functions\n",
    "\n",
    "Collection of functions to identify peaks in a series and the end of each peak recession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Events_Get_Peaks(Q, Qmin = None, tw = pd.Timedelta('12h')):\n",
    "    '''Find the peack values of the hydrographs of a serie\n",
    "    Params:\n",
    "        - Q: Pandas serie with the records.\n",
    "        - Qmin: The minimum value of Q to be considered a peak.\n",
    "            if None takes the 99th percentile of the series as the min\n",
    "        - tw: size of the ime window used to eliminate surrounding maximum values'''\n",
    "    if Qmin is None:\n",
    "        Qmin = np.percentile(Q.values[np.isfinite(Q.values)], 99)\n",
    "    #Find the maximum\n",
    "    Qmax = Q[Q>Qmin]\n",
    "    QmaxCopy = Qmax.copy()\n",
    "    #Search the maxium maximorums\n",
    "    Flag = True\n",
    "    PosMax = []\n",
    "    while Flag:\n",
    "        MaxIdx = Qmax.idxmax()\n",
    "        PosMax.append(MaxIdx)\n",
    "        Qmax[MaxIdx-tw:MaxIdx+tw] = -9\n",
    "        if Qmax.max() < Qmin: Flag = False\n",
    "    #Return the result\n",
    "    return QmaxCopy[PosMax].sort_index()\n",
    "\n",
    "def Events_Get_End(Q, Qmax, minDif = 0.04, minDistance = None,maxSearch = 10, Window = '1h'):\n",
    "    '''Find the end of each selected event in order to know the \n",
    "    longitude of each recession event.\n",
    "    Parameters: \n",
    "        - Q: Pandas series with the records.\n",
    "        - Qmax: Pandas series with the peak streamflows.\n",
    "        - minDif: The minimum difference to consider that a recession is over.\n",
    "    Optional:\n",
    "        - minDistance: minimum temporal distance between the peak and the end.\n",
    "        - maxSearch: maximum number of iterations to search for the end.\n",
    "        - Widow: Size of the temporal window used to smooth the streamflow \n",
    "            records before the difference estimation (pandas format).\n",
    "    Returns: \n",
    "        - Qend: The point indicating the en of the recession.'''\n",
    "    #Obtains the difference\n",
    "    X = Q.resample('1h').mean()\n",
    "    dX = X.values[1:] - X.values[:-1]\n",
    "    dX = pd.Series(dX, index=X.index[:-1])\n",
    "    #Obtains the points.\n",
    "    DatesEnds = []\n",
    "    Correct = []\n",
    "    for peakIndex in Qmax.index:\n",
    "        try:\n",
    "            a = dX[dX.index > peakIndex]\n",
    "            if minDistance is None:\n",
    "                DatesEnds.append(a[a>minDif].index[0])\n",
    "            else:\n",
    "                Dates = a[a>minDif].index\n",
    "                flag = True\n",
    "                c = 0\n",
    "                while flag:\n",
    "                    distancia = Dates[c] - peakIndex\n",
    "                    if distancia > minDistance:\n",
    "                        DatesEnds.append(Dates[c])\n",
    "                        flag= False\n",
    "                    c += 1\n",
    "                    if c>maxSearch: flag = False\n",
    "            Correct.append(0)\n",
    "        except:\n",
    "            DatesEnds.append(peakIndex)\n",
    "            Correct.append(1)\n",
    "    #Returns the pandas series with the values and end dates \n",
    "    Correct = np.array(Correct)\n",
    "    return pd.Series(Q[DatesEnds], index=DatesEnds), Qmax[Correct == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runoff analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Runoff_SeparateBaseflow(Qobs, Qsim):\n",
    "    '''From observed records obtain the baseflow and runoff streamflow records.\n",
    "    Parameters:\n",
    "        - Qobs: Observed record dt < 1h.\n",
    "        - Qsim: Simulated records dt < 1h.\n",
    "    Returns: \n",
    "        - Qh: Observed records at hourly scale.\n",
    "        - Qsh: Simulated records at a hourly scale.\n",
    "        - Qsep: Observed separated records at hourly scale'''\n",
    "    #Observed series to hourly scale.\n",
    "    Qh = Qobs.resample('1h').mean()\n",
    "    Qh[np.isnan(Qh)] = Qh.mean()\n",
    "    Qh[Qh<0] = Qh.mean()\n",
    "    Qsep = DigitalFilters(Qh, tipo = 'Nathan', a = 0.998)\n",
    "    #Pre-process of simulated series to hourly scale.\n",
    "    Qsh = Qsim.resample('1h').mean()\n",
    "    Qsh[np.isnan(Qsh)] = 0.0\n",
    "    #Return results\n",
    "    return Qh, Qsh, Qsep\n",
    "\n",
    "def Runoff_FindEvents(Qobs, Qsim, minTime = 1, minConcav = None, minPeak = None):\n",
    "    '''Separates runoff from baseflow and finds the events.\n",
    "    Parameters:\n",
    "        - Qobs: Hourly obseved streamflow.\n",
    "        - Qsim: Hourly simulated streamflow.\n",
    "        - minTime: minimum duration of the event.\n",
    "        - minConcav: minimum concavity of the event.\n",
    "        - minPeak: minimum value of the peakflows.\n",
    "    Returns: \n",
    "        - pos1: pandas index lists with the initial positions.\n",
    "        - pos2: pandas index lists with the end positions.'''\n",
    "    #Obtain the positions of the start and \n",
    "    pos1, pos2 = __Runoff_Get_Events__(Qsim, np.percentile(Qobs, 20))\n",
    "    pos1, pos2 = __Runoff_Del_Events__(Qobs, pos1, pos2, minTime=1, minConcav=minConcav, minPeak = minPeak)\n",
    "    #Returns results \n",
    "    return pos1, pos2\n",
    "\n",
    "def Runoff_CompleteAnalysis(Area, Qobs, Rain, Qsep, pos1, pos2, N=None, Nant = None):\n",
    "    '''Obtains the DataFrame with the resume of the RC analysis.\n",
    "    Parameters:\n",
    "        - Area: the area of the basin in km2.\n",
    "        - Qobs: Hourly observed streamflow.\n",
    "        - Rain: Hourly rainfall.\n",
    "        - Qsep: Hourly dataFrame with the separated flows.\n",
    "        - pos1: pandas index lists with the initial positions.\n",
    "        - pos2: pandas index lists with the end positions.\n",
    "        - N: Number of days to eval the rainfall between p1-N: p2.\n",
    "        - Nant: Number of antecedent days to eval the rainfall between p1-Nant : p1-N.\n",
    "    Results:\n",
    "        - DataFrame with the columns: RC, RainEvent, RainBefore, RainInt, Qmax'''\n",
    "    #Search for N\n",
    "    if N is None:\n",
    "        #Time window based on the basin area.\n",
    "        N = Area**0.2\n",
    "        N = np.floor(N) // 2 * 2 + 1\n",
    "        if N<3: N = 3\n",
    "        if N>11: N = 11        \n",
    "        Ndays = pd.Timedelta(str(N)+'d')\n",
    "        if Nant is None:\n",
    "            Nant = pd.Timedelta(str(N+3)+'d')\n",
    "    else:\n",
    "        Ndays = N\n",
    "        if Nant is None:\n",
    "            Nant = N + pd.Timedelta('3d')\n",
    "            \n",
    "    #Lists of data\n",
    "    RC = []\n",
    "    RainTot = []\n",
    "    Date = []\n",
    "    Qmax = []\n",
    "    RainInt = []\n",
    "    RainAnt = []\n",
    "\n",
    "    #Get Values for events\n",
    "    for pi,pf in zip(pos1, pos2):\n",
    "        #General variables obtention\n",
    "        Runoff = Qsep['Runoff'][pi:pf+Ndays].sum()*3600.\n",
    "        Rainfall = (Rain[pi-Ndays:pf].sum()/1000.)*(Area*1e6)\n",
    "        #Runoff and streamflow List updates\n",
    "        Qmax.append(Qobs[pi:pf].max())\n",
    "        RC.append(Runoff / Rainfall)\n",
    "        #Rainfall list updates\n",
    "        RainTot.append(Rain[pi-Ndays:pf].sum())\n",
    "        RainInt.append(Rain[pi-Ndays:pf].max())\n",
    "        RainAnt.append(Rain[pi-Ndays-Nant:pi-Ndays].sum())\n",
    "        #Dates.\n",
    "        Date.append(pi)\n",
    "    #Converts to arrays\n",
    "    RC = np.array(RC)\n",
    "    RainTot = np.array(RainTot)\n",
    "    RainInt = np.array(RainInt)\n",
    "    RainAnt = np.array(RainAnt)\n",
    "    Date = np.array(Date)\n",
    "    Qmax = np.array(Qmax)\n",
    "    #Select the correct values\n",
    "    p1 = np.where(np.isfinite(RC))[0]\n",
    "    p2 = np.where((RC[p1]<=1.0) & (RC[p1]>0.0))[0]\n",
    "    #Lo que es \n",
    "    RC = RC[p1[p2]]\n",
    "    RainTot = RainTot[p1[p2]]\n",
    "    RainInt = RainInt[p1[p2]]\n",
    "    RainAnt = RainAnt[p1[p2]]\n",
    "    Date = Date[p1[p2]]\n",
    "    Qmax = Qmax[p1[p2]]\n",
    "    #Los malos \n",
    "    pos = np.where((RC>0.04) & (RainTot<10))[0]\n",
    "    #Depura de nuevo \n",
    "    RC = np.delete(RC, pos)\n",
    "    RainTot = np.delete(RainTot, pos)\n",
    "    RainInt = np.delete(RainInt, pos)\n",
    "    RainAnt = np.delete(RainAnt, pos)\n",
    "    Date = np.delete(Date, pos)\n",
    "    Qmax = np.delete(Qmax, pos)\n",
    "    #Turns things into a DataFrame\n",
    "    Data = pd.DataFrame(\n",
    "        np.vstack([RC, RainTot, RainAnt, RainInt, Qmax]).T,\n",
    "        index= Date, \n",
    "        columns=['RC', 'RainEvent', 'RainBefore','RainInt','Qmax'])\n",
    "    return Data\n",
    "\n",
    "def Runoff_groupByRain(D, groupby = 'RainEvent' , bins = None,\n",
    "    Vmin=None, Vmax=None, Nb = 10, logx = True):\n",
    "    '''Group the values of RC in function of a variable.\n",
    "    Parameters:\n",
    "        - D: pandas Dataframe with the results from the RC analysis.\n",
    "        - groupby: name of the column to use for the groups.\n",
    "        - Vmin: minimum value to set the groups.\n",
    "        - Vmax: max value to set the groups.\n",
    "        - b: number of bins.\n",
    "        - logx: use or not logaritmic X axis.\n",
    "    Results:\n",
    "        - Dictionary with the RC by groups, P25, P50, P90, mean value of the variable\n",
    "        for grouping, Variable for groups.'''\n",
    "    #Change if the axis X is logarithm or not\n",
    "    if logx:\n",
    "        x = np.log(D[groupby])\n",
    "    else:\n",
    "        x = D[groupby]\n",
    "    #SEt max y min \n",
    "    if Vmin is None: Vmin = x.min()\n",
    "    if Vmax is None: Vmax = x.max()\n",
    "    #SEt the intervals\n",
    "    if bins is None:\n",
    "        b = np.linspace(Vmin, Vmax, Nb)\n",
    "    else:\n",
    "        b = bins\n",
    "    #Make the groups\n",
    "    DicStats = {'RC':[],'P25':[],'P75':[],'P50':[], 'X': [], groupby: []}    \n",
    "    for i,j in zip(b[:-1], b[1:]):\n",
    "        p = np.where((x>=i) & (x<=j))[0]\n",
    "        if p.size > 0:\n",
    "            DicStats['RC'].append(D['RC'][p])\n",
    "            DicStats['P25'].append(np.percentile(D['RC'][p], 25))\n",
    "            DicStats['P50'].append(np.percentile(D['RC'][p], 50))\n",
    "            DicStats['P75'].append(np.percentile(D['RC'][p], 75))\n",
    "            DicStats['X'].append((i+j)/2.)\n",
    "            DicStats[groupby].append(x[p])\n",
    "    return DicStats\n",
    "#-------------------------------------------------------------------------------------------\n",
    "## Backgroudn functions.\n",
    "\n",
    "def __Runoff_Get_Events__(Q, Umbral):\n",
    "    '''Obtais the initia and end dates of the events related to \n",
    "    a time series based on the results from the Asynch 190.\n",
    "    Parameters:\n",
    "        - Q: pandas series with the streamflow (simulated from asynch 190 no infiltration).\n",
    "        - perc: percentile used to stablish runoff occurrence.\n",
    "    Returns:\n",
    "        - pos1: initial date of each event.\n",
    "        - pos2: end date of each event'''    \n",
    "    #Treshold and positions with values over it\n",
    "    pos = np.where(Q.values > Umbral)[0]\n",
    "    #Positions start and end.\n",
    "    Dpos = pos[1:] - pos[:-1]\n",
    "    Dpos1 = pd.Series(Dpos, Q.index[pos[1:]])\n",
    "    pos1 = Dpos1[Dpos1>1].index\n",
    "    pos1 = pos1.insert(0, Q.index[pos][0])\n",
    "    pos1 = pos1[:-1]\n",
    "    Dpos2 = pd.Series(Dpos, Q.index[pos[:-1]])\n",
    "    pos2 = Dpos2[Dpos2>1].index\n",
    "    #returns results \n",
    "    return pos1, pos2\n",
    "\n",
    "def __Runoff_Get_eventsPeaks__(Q, pos1, pos2):\n",
    "    '''Obtains the peaks of the observed events selected by the \n",
    "    criteria of the asynch 190 model\n",
    "    PArameters:\n",
    "        - Q: Pandas series qwith the observed data.\n",
    "        - pos1: list with the start of the peaks.\n",
    "        - pos2: list with the end of the peaks.\n",
    "    Returns:\n",
    "        - List with the peaks corresponding to the events.'''\n",
    "    #Peak at each event \n",
    "    Peaks = []\n",
    "    for p1, p2 in zip(pos1, pos2):\n",
    "        Peaks.append(np.nanmax(Q[p1:p2].values))\n",
    "    return Peaks\n",
    "\n",
    "def __Runoff_Del_Events__(Q, pos1, pos2, minTime = 2.5, minPeak = None, minConcav = None):\n",
    "    '''Eliminates events from the selected initial peaks based on different \n",
    "    aspects such as min time of the event, min peak and the concativity.\n",
    "    Parameters:\n",
    "        - Q: pandas series with the observed streamflow.\n",
    "        - pos1: Pandas indexes with the start of the events.\n",
    "        - pos2: Pandas indexes with the end of the events.\n",
    "        - minTime: minimum time (days) of the duration  of the hydrographs.\n",
    "        - minPeak: minim value of the peak at the hydrographs.\n",
    "        - minConcat: minimum concativity for the hydrograph (suggested: 10).\n",
    "    Returns:\n",
    "        - starts: pandas index with the corrected starts.\n",
    "        - ends: pandas indexes with the corrected ends.'''\n",
    "    #Eliminates events based on their duration\n",
    "    if minTime is not None:\n",
    "        #Obtains the duration\n",
    "        Td = pos2 - pos1\n",
    "        Td = Td.total_seconds()/(3600*24)\n",
    "        Td = Td.values\n",
    "        #Eliminates\n",
    "        p = np.where(Td<minTime)[0]\n",
    "        pos1 = pos1.delete(p)\n",
    "        pos2 = pos2.delete(p)\n",
    "    #Eliminates events based on the peak flow\n",
    "    if minPeak is not None:\n",
    "        #Obtains peaks\n",
    "        Peaks = Series_Get_eventsPeaks(Q, pos1, pos2)\n",
    "        Peaks = np.array(Peaks)\n",
    "        #Eliminates\n",
    "        p = np.where(Peaks<minPeak)[0]\n",
    "        pos1 = pos1.delete(p)\n",
    "        pos2 = pos2.delete(p)\n",
    "    #Eliminates events based on the concavity criterion\n",
    "    if minConcav is not None:\n",
    "        #Obtains the concativity series \n",
    "        Concav = Q.resample('5h').mean().diff(2)\n",
    "        Concav = Series_Get_eventsPeaks(Concav, pos1, pos2)\n",
    "        #Eliminates\n",
    "        p = np.where(np.array(Concav)<minConcav)[0]\n",
    "        pos1 = pos1.delete(p)\n",
    "        pos2 = pos2.delete(p)\n",
    "    #Returns the result\n",
    "    return pos1, pos2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recession analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to obtain a\n",
    "def Recession_NDF_method(l):\n",
    "    '''l[0]: np.ndarray of the streamflow data.\n",
    "    l[1]: parameter B between 0 and 5'''\n",
    "    \n",
    "    # Function to obtains A for a given B (l[1])\n",
    "    def Estimate_A(Q,B,dt):\n",
    "        e1 = np.nansum((Q.values[:-1] - Q.values[1:]))\n",
    "        e2 = dt * np.nansum(((Q.values[:-1] - Q.values[1:])/2.)**B)        \n",
    "        return e1/e2\n",
    "    \n",
    "    # Estimates Q for the pair B and A    \n",
    "    def Estimate_Q(Q, B, A):\n",
    "        '''Obtaines the estimated Q for a given A and B\n",
    "        Parameters:\n",
    "        - Qo: the initial value of the analyzed peak.\n",
    "        - t: Vector with the elapsed time.'''\n",
    "        #Convert time vector to elapsed time in seconds.\n",
    "        t = Q.index.astype('int64') / 1e9\n",
    "        t = (t.values - t.values[0])/3600.\n",
    "        Qo = Q.values[0]\n",
    "        # Obtains the estimted Qs\n",
    "        return Qo * (1 - ( (1.-B)*A*t / Qo**(1.-B) )) ** (1./(1.-B))\n",
    "    \n",
    "    def Estimate_error(Qobs, Qsim):\n",
    "        '''Estimates the total percentage error obtained with the pair\n",
    "        A and B'''\n",
    "        Vsim = Qsim.sum()\n",
    "        Vobs = Qobs.sum()\n",
    "        return (Vsim - Vobs) / Vsim\n",
    "    \n",
    "    #Obtains the time delta \n",
    "    dt = l[0].index[1] - l[0].index[0]\n",
    "    dt = dt.value / 1e9\n",
    "    #Estimates A \n",
    "    A = Estimate_A(l[0],l[1],dt)\n",
    "    #Estimaest Q\n",
    "    Qsim = Estimate_Q(l[0],l[1], A)\n",
    "    CountNaN = Qsim[np.isnan(Qsim)].size\n",
    "    #Estimate error\n",
    "    if CountNaN  == 0:\n",
    "        E = Estimate_error(l[0],Qsim)\n",
    "    else:\n",
    "        E = 1000\n",
    "    return A, E, Qsim\n",
    "\n",
    "# search B for recession \n",
    "def Recession_Search_NDF(Q,Initial = 0, Long=1 ,process = 8, Window = 1, step = 0.01):\n",
    "    '''Search for the optimum value of B and A for a hydrograph\n",
    "    Parameters:\n",
    "        - Initial: Initial point oscillates between 0 and 168h.\n",
    "        - Long: recession longitude oscillates between 4 and 12 days.\n",
    "        - process: total number of processors to do the analysis.'''\n",
    "    #Movement of the initial and finish time \n",
    "    dis_i = pd.Timedelta(hours = Initial)\n",
    "    dis_f = pd.Timedelta(hours = 24*Long)\n",
    "    #Take a portion of the recession curve\n",
    "    X = Q[Q.idxmax()+dis_i:Q.idxmax()+dis_f+dis_i]\n",
    "    # Excercise to obtain A and B for a streamflow record.\n",
    "    L = []\n",
    "    B = np.arange(0, 5., step)\n",
    "    for b in B:\n",
    "        L.append([X, b])\n",
    "    p = Pool(processes=process)\n",
    "    Res = p.map(NDF_method, L)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    #Error selection\n",
    "    Error = np.abs([i[1] for i in Res])\n",
    "    PosEr = np.argmin(Error)\n",
    "    #Return: B, A, E and Qsim\n",
    "    return B[PosEr], Res[PosEr][0], Error[PosEr], pd.Series(Res[PosEr][2], X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
